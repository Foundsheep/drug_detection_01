{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_x_train = Path(\"./data_rosa/X_train\")\n",
    "folder_x_test = Path(\"./data_rosa/X_test\")\n",
    "folder_others = Path(\"./data\")\n",
    "\n",
    "paths_x_train = list(folder_x_train.glob(\"./*.txt\"))\n",
    "paths_x_test = list(folder_x_test.glob(\"./*.txt\"))\n",
    "paths_others = list(folder_others.glob(\"./*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>Li</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>Fe</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RM_NIST183</td>\n",
       "      <td>0.01914</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.066412</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RM_OREAS751</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.00772</td>\n",
       "      <td>0.084048</td>\n",
       "      <td>0.333894</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.501341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RM_OREAS752</td>\n",
       "      <td>0.00707</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>0.086271</td>\n",
       "      <td>0.341280</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.506016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM_OREAS753</td>\n",
       "      <td>0.01020</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.00109</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.344505</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.507452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RM_OREAS999</td>\n",
       "      <td>0.02670</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.00473</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.123796</td>\n",
       "      <td>0.300238</td>\n",
       "      <td>0.017416</td>\n",
       "      <td>0.510159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample       Li       Na        Mg         K       Ca        Al  \\\n",
       "0   RM_NIST183  0.01914  0.001484  0.00000  0.066412  0.00000  0.000000   \n",
       "1  RM_OREAS751  0.00468  0.024700  0.00293  0.023900  0.00772  0.084048   \n",
       "2  RM_OREAS752  0.00707  0.027000  0.00047  0.021000  0.00215  0.086271   \n",
       "3  RM_OREAS753  0.01020  0.021600  0.00011  0.019500  0.00109  0.086800   \n",
       "4  RM_OREAS999  0.02670  0.006930  0.00473  0.005220  0.00481  0.123796   \n",
       "\n",
       "         Si        Fe    others  \n",
       "0  0.000000  0.000000  0.912964  \n",
       "1  0.333894  0.016787  0.501341  \n",
       "2  0.341280  0.008743  0.506016  \n",
       "3  0.344505  0.008743  0.507452  \n",
       "4  0.300238  0.017416  0.510159  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_path = \"./data_rosa/Y/concentration_withDummy.xlsx\"\n",
    "\n",
    "df_y = pd.read_excel(y_path, usecols=range(1, 10), nrows=16)\n",
    "df_y = df_y.fillna(0)\n",
    "df_y.iloc[:, 1:] = df_y.iloc[:, 1:] / 100\n",
    "df_y[\"others\"] = df_y.iloc[:, 1:].apply(lambda x: 1 - sum(x), axis=1)\n",
    "\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_for_whole_dataset(path_list):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i, p in enumerate(path_list):\n",
    "        for sample_name in df_y[\"sample\"]:\n",
    "            if p.name.startswith(sample_name):\n",
    "                col_1 = []\n",
    "                col_2 = []\n",
    "                col_3 = []\n",
    "                col_4 = []\n",
    "                col_5 = []\n",
    "                col_6 = []\n",
    "\n",
    "                with open(p, \"r\") as f:\n",
    "                    for idx, line in enumerate(f):\n",
    "                        if idx > 31:\n",
    "                            tmp_nums = line.split()\n",
    "                            \n",
    "                            col_1.append(float(tmp_nums[0]))\n",
    "                            col_2.append(float(tmp_nums[1]))\n",
    "                            col_3.append(float(tmp_nums[2]))\n",
    "                            col_4.append(float(tmp_nums[3]))\n",
    "                            col_5.append(float(tmp_nums[4]))\n",
    "                            col_6.append(float(tmp_nums[5]))\n",
    "\n",
    "                assert len(col_1) == len(col_2) == len(col_3) == len(col_4) == len(col_5) == len(col_6)\n",
    "\n",
    "                tmp_df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"intensity_1\": col_2,\n",
    "                        \"intensity_2\": col_3,\n",
    "                        \"intensity_3\": col_4,\n",
    "                        \"intensity_4\": col_5,\n",
    "                        \"intensity_5\": col_6,\n",
    "                    },\n",
    "                    index=col_1\n",
    "                )\n",
    "                tmp_df[\"set_num\"] = i\n",
    "                tmp_df[\"target_file_name\"] = sample_name\n",
    "                tmp_df[\"data_file_name\"] = p.name\n",
    "                \n",
    "                df = pd.concat([df, tmp_df], axis=0)\n",
    "                break\n",
    "                \n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"index\": \"wavelength\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_df_for_whole_dataset(paths_x_train)\n",
    "df_test = create_df_for_whole_dataset(paths_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COLS = [\"intensity_1\", \"intensity_2\", \"intensity_3\", \"intensity_4\", \"intensity_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[USE_COLS])\n",
    "X_train = scaler.transform(df_train[USE_COLS])\n",
    "X_test = scaler.transform(df_test[USE_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 61440)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, [1,3,4]].mean(axis=1).reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipeline\n",
    "def convert_data_to_X_and_y(param_df, param_X, param_df_y, use_channel=None):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for set_num in param_df[\"set_num\"].unique():\n",
    "        # tmp mask\n",
    "        tmp_mask = param_df[\"set_num\"] == set_num\n",
    "        \n",
    "        # get specific X data\n",
    "        X_tmp = param_X[tmp_mask]\n",
    "        if isinstance(use_channel, list):\n",
    "            X_tmp = X_tmp[:, use_channel].mean(axis=1).reshape(1, -1)\n",
    "        elif isinstance(use_channel, int):\n",
    "            X_tmp = X_tmp[:, use_channel].reshape(1, -1)\n",
    "        else:\n",
    "            X_tmp\n",
    "        \n",
    "        # get specific y data\n",
    "        tmp_df = param_df[tmp_mask]\n",
    "        tmp_sample = tmp_df[\"target_file_name\"].iloc[0]\n",
    "        tmp_y = param_df_y[param_df_y[\"sample\"] == tmp_sample]\n",
    "        y_tmp = tmp_y.iloc[0, 1:].astype(float).values\n",
    "        \n",
    "        # gather\n",
    "        X_list.append(X_tmp)\n",
    "        y_list.append(y_tmp)\n",
    "        \n",
    "    return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train, ys_train = convert_data_to_X_and_y(df_train, X_train, df_y, use_channel=0)\n",
    "Xs_test, ys_test = convert_data_to_X_and_y(df_test, X_test, df_y, use_channel=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, Xs, ys):\n",
    "        super().__init__()\n",
    "        self.Xs = Xs\n",
    "        self.ys = ys\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Xs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.Xs[idx]), torch.Tensor(self.ys[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = SensorDataset(Xs_train, ys_train)\n",
    "ds_test = SensorDataset(Xs_test, ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(\n",
    "    dataset=ds_train,\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dl_test = torch.utils.data.DataLoader(\n",
    "    dataset=ds_test,\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class DrugClassifierCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DrugClassifierCNN, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.conv1 = nn.Conv1d(1, 1, 3, padding=0)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 3, padding=0)\n",
    "        self.conv3 = nn.Conv1d(1, 1, 3, padding=0)\n",
    "        self.conv4 = nn.Conv1d(1, 1, 3, padding=0)\n",
    "        self.fc1 = nn.Linear(766, 128)\n",
    "        self.fc2 = nn.Linear(128, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = DrugClassifierCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99353"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "TOLERANCE_VALUE = 10\n",
    "TOLERANCE = TOLERANCE_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH   1\tLoss train 0.0277 | valid 0.0847\n",
      "EPOCH   2\tLoss train 0.0677 | valid 0.0827\n",
      "EPOCH   3\tLoss train 0.0255 | valid 0.0806\n",
      "EPOCH   4\tLoss train 0.0626 | valid 0.0783\n",
      "EPOCH   5\tLoss train 0.0617 | valid 0.0759\n",
      "EPOCH   6\tLoss train 0.0582 | valid 0.0733\n",
      "EPOCH   7\tLoss train 0.0592 | valid 0.0705\n",
      "EPOCH   8\tLoss train 0.0533 | valid 0.0676\n",
      "EPOCH   9\tLoss train 0.0506 | valid 0.0645\n",
      "EPOCH  10\tLoss train 0.0479 | valid 0.0613\n",
      "EPOCH  11\tLoss train 0.0461 | valid 0.0579\n",
      "EPOCH  12\tLoss train 0.0142 | valid 0.0544\n",
      "EPOCH  13\tLoss train 0.0391 | valid 0.0509\n",
      "EPOCH  14\tLoss train 0.0361 | valid 0.0474\n",
      "EPOCH  15\tLoss train 0.0408 | valid 0.0440\n",
      "EPOCH  16\tLoss train 0.0100 | valid 0.0404\n",
      "EPOCH  17\tLoss train 0.0275 | valid 0.0372\n",
      "EPOCH  18\tLoss train 0.0313 | valid 0.0340\n",
      "EPOCH  19\tLoss train 0.0232 | valid 0.0310\n",
      "EPOCH  20\tLoss train 0.0209 | valid 0.0282\n",
      "EPOCH  21\tLoss train 0.0198 | valid 0.0256\n",
      "EPOCH  22\tLoss train 0.0079 | valid 0.0231\n",
      "EPOCH  23\tLoss train 0.0189 | valid 0.0210\n",
      "EPOCH  24\tLoss train 0.0172 | valid 0.0192\n",
      "EPOCH  25\tLoss train 0.0156 | valid 0.0175\n",
      "EPOCH  26\tLoss train 0.0141 | valid 0.0160\n",
      "EPOCH  27\tLoss train 0.0129 | valid 0.0146\n",
      "EPOCH  28\tLoss train 0.0096 | valid 0.0134\n",
      "EPOCH  29\tLoss train 0.0078 | valid 0.0124\n",
      "EPOCH  30\tLoss train 0.0076 | valid 0.0115\n",
      "EPOCH  31\tLoss train 0.0066 | valid 0.0107\n",
      "EPOCH  32\tLoss train 0.0069 | valid 0.0099\n",
      "EPOCH  33\tLoss train 0.0064 | valid 0.0093\n",
      "EPOCH  34\tLoss train 0.0074 | valid 0.0087\n",
      "EPOCH  35\tLoss train 0.0049 | valid 0.0082\n",
      "EPOCH  36\tLoss train 0.0053 | valid 0.0078\n",
      "EPOCH  37\tLoss train 0.0047 | valid 0.0074\n",
      "EPOCH  38\tLoss train 0.0136 | valid 0.0069\n",
      "EPOCH  39\tLoss train 0.0042 | valid 0.0066\n",
      "EPOCH  40\tLoss train 0.0142 | valid 0.0063\n",
      "EPOCH  41\tLoss train 0.0145 | valid 0.0060\n",
      "EPOCH  42\tLoss train 0.0148 | valid 0.0058\n",
      "EPOCH  43\tLoss train 0.0046 | valid 0.0056\n",
      "EPOCH  44\tLoss train 0.0035 | valid 0.0054\n",
      "EPOCH  45\tLoss train 0.0031 | valid 0.0052\n",
      "EPOCH  46\tLoss train 0.0042 | valid 0.0051\n",
      "EPOCH  47\tLoss train 0.0030 | valid 0.0050\n",
      "EPOCH  48\tLoss train 0.0031 | valid 0.0048\n",
      "EPOCH  49\tLoss train 0.0030 | valid 0.0047\n",
      "EPOCH  50\tLoss train 0.0027 | valid 0.0046\n",
      "EPOCH  51\tLoss train 0.0027 | valid 0.0044\n",
      "EPOCH  52\tLoss train 0.0029 | valid 0.0043\n",
      "EPOCH  53\tLoss train 0.0168 | valid 0.0042\n",
      "EPOCH  54\tLoss train 0.0025 | valid 0.0041\n",
      "EPOCH  55\tLoss train 0.0025 | valid 0.0041\n",
      "EPOCH  56\tLoss train 0.0027 | valid 0.0040\n",
      "EPOCH  57\tLoss train 0.0024 | valid 0.0040\n",
      "EPOCH  58\tLoss train 0.0026 | valid 0.0039\n",
      "EPOCH  59\tLoss train 0.0024 | valid 0.0038\n",
      "EPOCH  60\tLoss train 0.0025 | valid 0.0038\n",
      "EPOCH  61\tLoss train 0.0025 | valid 0.0037\n",
      "EPOCH  62\tLoss train 0.0029 | valid 0.0037\n",
      "EPOCH  63\tLoss train 0.0024 | valid 0.0036\n",
      "EPOCH  64\tLoss train 0.0024 | valid 0.0036\n",
      "EPOCH  65\tLoss train 0.0179 | valid 0.0035\n",
      "EPOCH  66\tLoss train 0.0022 | valid 0.0035\n",
      "EPOCH  67\tLoss train 0.0028 | valid 0.0035\n",
      "EPOCH  68\tLoss train 0.0023 | valid 0.0034\n",
      "EPOCH  69\tLoss train 0.0181 | valid 0.0034\n",
      "EPOCH  70\tLoss train 0.0021 | valid 0.0034\n",
      "EPOCH  71\tLoss train 0.0021 | valid 0.0033\n",
      "EPOCH  72\tLoss train 0.0182 | valid 0.0033\n",
      "EPOCH  73\tLoss train 0.0183 | valid 0.0033\n",
      "EPOCH  74\tLoss train 0.0021 | valid 0.0033\n",
      "EPOCH  75\tLoss train 0.0022 | valid 0.0032\n",
      "EPOCH  76\tLoss train 0.0184 | valid 0.0032\n",
      "EPOCH  77\tLoss train 0.0184 | valid 0.0032\n",
      "EPOCH  78\tLoss train 0.0021 | valid 0.0032\n",
      "EPOCH  79\tLoss train 0.0025 | valid 0.0032\n",
      "EPOCH  80\tLoss train 0.0025 | valid 0.0032\n",
      "EPOCH  81\tLoss train 0.0020 | valid 0.0032\n",
      "EPOCH  82\tLoss train 0.0021 | valid 0.0032\n",
      "EPOCH  83\tLoss train 0.0021 | valid 0.0032\n",
      "EPOCH  84\tLoss train 0.0021 | valid 0.0032\n",
      "EPOCH  85\tLoss train 0.0020 | valid 0.0032\n",
      "EPOCH  86\tLoss train 0.0025 | valid 0.0032\n",
      "EPOCH  87\tLoss train 0.0025 | valid 0.0032\n",
      "EPOCH  88\tLoss train 0.0025 | valid 0.0031\n",
      "EPOCH  89\tLoss train 0.0019 | valid 0.0031\n",
      "EPOCH  90\tLoss train 0.0025 | valid 0.0031\n",
      "EPOCH  91\tLoss train 0.0025 | valid 0.0031\n",
      "EPOCH  92\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH  93\tLoss train 0.0186 | valid 0.0031\n",
      "EPOCH  94\tLoss train 0.0187 | valid 0.0030\n",
      "EPOCH  95\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH  96\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH  97\tLoss train 0.0020 | valid 0.0030\n",
      "EPOCH  98\tLoss train 0.0019 | valid 0.0031\n",
      "EPOCH  99\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH 100\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH 101\tLoss train 0.0024 | valid 0.0031\n",
      "EPOCH 102\tLoss train 0.0186 | valid 0.0030\n",
      "EPOCH 103\tLoss train 0.0024 | valid 0.0031\n",
      "EPOCH 104\tLoss train 0.0186 | valid 0.0030\n",
      "EPOCH 105\tLoss train 0.0024 | valid 0.0030\n",
      "EPOCH 106\tLoss train 0.0019 | valid 0.0031\n",
      "EPOCH 107\tLoss train 0.0020 | valid 0.0030\n",
      "EPOCH 108\tLoss train 0.0024 | valid 0.0031\n",
      "EPOCH 109\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH 110\tLoss train 0.0020 | valid 0.0031\n",
      "EPOCH 111\tLoss train 0.0019 | valid 0.0031\n",
      "EPOCH 112\tLoss train 0.0019 | valid 0.0031\n",
      "EPOCH 113\tLoss train 0.0018 | valid 0.0031\n",
      "EPOCH 114\tLoss train 0.0019 | valid 0.0031\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"runs/drug_detection_{timestamp}\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "step_interval_to_record = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch+1:3d}\", end=\"\\t\")\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(dl_train):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimiser.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % step_interval_to_record == step_interval_to_record - 1:\n",
    "            last_loss = running_loss / step_interval_to_record\n",
    "            # print(f\"   step: {i+1:3d} | loss: {last_loss:4f}\")\n",
    "            tb_x = epoch * len(dl_train) + i + 1\n",
    "            writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    avg_last_loss = last_loss\n",
    "    \n",
    "    # evaluation\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vi, vdata in enumerate(dl_test):\n",
    "            vinputs, vlabels = vdata\n",
    "            vouputs = model(vinputs)\n",
    "            vloss = loss_fn(vouputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "            \n",
    "    avg_v_loss = running_vloss / (vi + 1)\n",
    "    print(f\"Loss train {avg_last_loss:.4f} | valid {avg_v_loss:.4f}\")\n",
    "    \n",
    "    writer.add_scalars(\n",
    "        \"Training vs Validation Loss\",\n",
    "        {\n",
    "            \"Training\": avg_last_loss,\n",
    "            \"Validation\": avg_v_loss,\n",
    "        },\n",
    "        epoch + 1\n",
    "    )\n",
    "    writer.flush()\n",
    "    \n",
    "    # best performance\n",
    "    if avg_v_loss < best_vloss:\n",
    "        best_vloss = avg_v_loss\n",
    "        model_path = f\"{log_dir}/best.pt\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        TOLERANCE = TOLERANCE_VALUE\n",
    "    else:\n",
    "        TOLERANCE -= 1\n",
    "    \n",
    "    if TOLERANCE == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Li</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>Fe</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.00650</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred</th>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>0.02117</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.031997</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.788684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Li       Na        Mg         K        Ca        Al        Si  \\\n",
       "y_true  0.024400  0.006800  0.00650  0.010600  0.009700  0.000000  0.000000   \n",
       "y_pred  0.027229  0.023428  0.02117  0.025226  0.014682  0.031997  0.052396   \n",
       "\n",
       "              Fe    others  \n",
       "y_true  0.000000  0.942000  \n",
       "y_pred  0.015188  0.788684  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Li</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>Fe</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.00650</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred</th>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>0.02117</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.031997</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>0.788682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Li       Na        Mg         K        Ca        Al        Si  \\\n",
       "y_true  0.024400  0.006800  0.00650  0.010600  0.009700  0.000000  0.000000   \n",
       "y_pred  0.027229  0.023427  0.02117  0.025226  0.014682  0.031997  0.052396   \n",
       "\n",
       "              Fe    others  \n",
       "y_true  0.000000  0.942000  \n",
       "y_pred  0.015189  0.788682  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Li</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>Fe</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred</th>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>0.015187</td>\n",
       "      <td>0.788687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Li       Na         Mg         K        Ca        Al        Si  \\\n",
       "y_true  0.024400  0.006800  0.006500  0.010600  0.009700  0.000000  0.000000   \n",
       "y_pred  0.027229  0.023429  0.021169  0.025225  0.014682  0.031995  0.052396   \n",
       "\n",
       "              Fe    others  \n",
       "y_true  0.000000  0.942000  \n",
       "y_pred  0.015187  0.788687  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for d in dl_test:\n",
    "        tmp_x_test, y_true = d\n",
    "        y_pred = model(tmp_x_test)\n",
    "        test_loss += loss_fn(y_pred, y_true)\n",
    "        \n",
    "        tmp_df = pd.DataFrame(\n",
    "            {\n",
    "                \"y_true\": y_true.squeeze().numpy(),\n",
    "                \"y_pred\": y_pred.squeeze().numpy()\n",
    "            },\n",
    "        ).T\n",
    "        tmp_df.columns = df_y.columns[1:]\n",
    "        display(tmp_df)\n",
    "        # print(\"------------------------------------------------------------------------------------\")\n",
    "        # print(f\"{y_true = }\")\n",
    "        # print(f\"{y_pred = }\")\n",
    "        # print()\n",
    "print(f'Test Loss: {test_loss / len(dl_test):.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
